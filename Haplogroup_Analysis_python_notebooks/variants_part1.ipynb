{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a61f4d-8d66-4289-ac45-cb8a1452e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f28e94-abca-4545-80fd-6383fa922ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91255\n",
      "90002\n"
     ]
    }
   ],
   "source": [
    "variantDF1= pd.read_csv(\"/Users/loftum/Desktop/LeeLab/LeonardoDaVinci/JCVI/ISOGG_SNP_Index_260821.csv\")\n",
    "goodRows=[]\n",
    "for row in variantDF1.index:\n",
    "    if '.' in str(variantDF1.at[row,'Build 38 #']) or 'del' in str(variantDF1.at[row,'Mutation info']):\n",
    "        continue\n",
    "    else:\n",
    "        goodRows.append(row)\n",
    "\n",
    "\n",
    "variantDF11 = variantDF1.loc[goodRows].copy()\n",
    "markerDict1 = collections.Counter(variantDF11['Name'])\n",
    "print(len(markerDict1))\n",
    "\n",
    "markerDict2 = {x:y for x,y in markerDict1.items() if y ==1}\n",
    "print(len(markerDict2))\n",
    "\n",
    "goodMarkers=[]\n",
    "for row in variantDF11.index:\n",
    "    if variantDF11.at[row,'Name'] in markerDict2:\n",
    "        goodMarkers.append(row)\n",
    "\n",
    "variantDF = variantDF11.loc[goodMarkers].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a7b95f-28a6-49bf-951a-d7a31cde9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72641/72641 [02:27<00:00, 492.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "positionDict={}\n",
    "for position in tqdm(set(variantDF['Build 38 #'])):\n",
    "    tempVariantDF = variantDF[variantDF['Build 38 #']==position].copy()\n",
    "    try:\n",
    "        positionDict[position]={'haploGroups':list(set(tempVariantDF['Haplogroup'])),'MarkerID':list(tempVariantDF['Name'])[0], 'Ancestral':list(tempVariantDF['Mutation info'])[0].split(\"->\")[0], 'Derived':list(tempVariantDF['Mutation info'])[0].split(\"->\")[1]}\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(positionDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57bd753d-7125-4e60-b8b0-04debe1ba9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR-0023.map5.sg5.vcf\n",
      "12444\n",
      "SR-0024.map5.sg5.vcf\n",
      "13055\n",
      "SR-0012.map5.sg5.vcf\n",
      "180\n",
      "SR-0015.map5.sg5.vcf\n",
      "2882666\n",
      "WTF SR-0015.map5.sg5.vcf I2a1b1 6892475 T . TC TCC\n",
      "WTF SR-0015.map5.sg5.vcf J1a2a1a2c~ 8205135 G . J A\n",
      "WTF SR-0015.map5.sg5.vcf J1a2a1a2d2b2b2c2~ 11865699 G . C T\n",
      "WTF SR-0015.map5.sg5.vcf D1a2a2b~ 12059415 C . T A\n",
      "WTF SR-0015.map5.sg5.vcf H3b1 16818281 G T G C\n",
      "WTF SR-0015.map5.sg5.vcf I2a2b1e1~ 17356300 C A C T\n",
      "WTF SR-0015.map5.sg5.vcf I2a1b1a2b1a1a2c~ 19497475 C A C T\n",
      "WTF SR-0015.map5.sg5.vcf C 19648238 C . G A\n",
      "WTF SR-0015.map5.sg5.vcf G2a2b2a1a1b1a1b1a3~ 21212500 A . C T\n",
      "11422-0008.map5.sg5.vcf\n",
      "167\n",
      "5540-011.map5.sg5.vcf\n",
      "2093\n",
      "SR-0007.map5.sg5.vcf\n",
      "1732\n",
      "SR-0025.map5.sg5.vcf\n",
      "867227\n",
      "WTF SR-0025.map5.sg5.vcf J1a2a1a2d2b2b2c2~ 11865699 G . C T\n",
      "WTF SR-0025.map5.sg5.vcf C2a1a2a2b1~ 12122652 T C T A\n",
      "WTF SR-0025.map5.sg5.vcf J2b2a1a1b1a~ 16123287 A G A C\n",
      "SR-0022.map5.sg5.vcf\n",
      "389986\n",
      "WTF SR-0022.map5.sg5.vcf H2a1~ 11865554 C A C G\n",
      "SR-0006.map5.sg5.vcf\n",
      "351\n",
      "SR-0001.map5.sg5.vcf\n",
      "99493\n",
      "SR-0014.map5.sg5.vcf\n",
      "3443762\n",
      "WTF SR-0014.map5.sg5.vcf G2a2b1b1a1c1a~ 7408137 G . C T\n",
      "WTF SR-0014.map5.sg5.vcf D1 7882748 A G A T\n",
      "WTF SR-0014.map5.sg5.vcf J1a2a1a2c~ 8205135 G . J A\n",
      "WTF SR-0014.map5.sg5.vcf G2a2b2a1a1a1b1c4 8468468 A . C G\n",
      "WTF SR-0014.map5.sg5.vcf O(Notes) 8751591 C . G A\n",
      "WTF SR-0014.map5.sg5.vcf D1a2a2b~ 12059415 C . T A\n",
      "WTF SR-0014.map5.sg5.vcf S1d 12838912 C A C T\n",
      "WTF SR-0014.map5.sg5.vcf I2a1a2a1a2a1 13653239 T . T- C\n",
      "WTF SR-0014.map5.sg5.vcf R1b1a1b1a1a2c1b2a1a1 15458916 G . C T\n",
      "WTF SR-0014.map5.sg5.vcf R1a1a 19571282 G . 4G 3G\n",
      "WTF SR-0014.map5.sg5.vcf G2a2b2a1a1b1a1b1a3~ 21212500 A . C T\n",
      "WTF SR-0014.map5.sg5.vcf G2a2b2a1a1c2b1b4 21623245 C . G A\n",
      "SR-0013.map5.sg5.vcf\n",
      "4033989\n",
      "WTF SR-0013.map5.sg5.vcf E1b1a1a1a1c2c3 7034213 A . AGTG AG\n",
      "WTF SR-0013.map5.sg5.vcf I2a2b1i~ 7145729 T . G A\n",
      "WTF SR-0013.map5.sg5.vcf Q2 7882996 A T A G\n",
      "WTF SR-0013.map5.sg5.vcf J1a2a1a2c~ 8205135 G . J A\n",
      "WTF SR-0013.map5.sg5.vcf G2a2b1b1a1c1a~ 8598015 T . G A\n",
      "WTF SR-0013.map5.sg5.vcf D1a2a2b~ 12059415 C . T A\n",
      "WTF SR-0013.map5.sg5.vcf J2b2a~ 14423457 C A C T\n",
      "WTF SR-0013.map5.sg5.vcf G2a2b2b1a1a2a1b~ 14431321 C A C G\n",
      "WTF SR-0013.map5.sg5.vcf BT 14696889 C A T C\n",
      "WTF SR-0013.map5.sg5.vcf R1b1a1b1a1a2c1b2a1a1 15458916 G . C T\n",
      "WTF SR-0013.map5.sg5.vcf H3 16705652 G A G C\n",
      "WTF SR-0013.map5.sg5.vcf G2a2b2a1a1b1a1a2b1a2 18953325 C . G T\n",
      "WTF SR-0013.map5.sg5.vcf C 19648238 C . G A\n",
      "WTF SR-0013.map5.sg5.vcf J1 19991972 G T G A\n",
      "WTF SR-0013.map5.sg5.vcf R1b1b2a2b1 21390228 G T G A\n",
      "11422-0009.map5.sg5.vcf\n",
      "0\n",
      "5540-008.map5.sg5.vcf\n",
      "12267\n",
      "SR-0019.map5.sg5.vcf\n",
      "5380\n",
      "11422-0003.map5.sg5.vcf\n",
      "215\n",
      "11422-0004.map5.sg5.vcf\n",
      "455\n",
      "11422-0010.map5.sg5.vcf\n",
      "19122\n",
      "5540-009.map5.sg5.vcf\n",
      "16447\n",
      "SR-0018.map5.sg5.vcf\n",
      "3448\n",
      "11422-0005.map5.sg5.vcf\n",
      "0\n",
      "11422-0002.map5.sg5.vcf\n",
      "0\n",
      "SR-0008.map5.sg5.vcf\n",
      "340\n",
      "11422-0007.map5.sg5.vcf\n",
      "0\n",
      "11422-0006.map5.sg5.vcf\n",
      "0\n",
      "11422-0001.map5.sg5.vcf\n",
      "302\n",
      "SR-0009.map5.sg5.vcf\n",
      "23501\n",
      "SR-0020.map5.sg5.vcf\n",
      "3550\n",
      "SR-0027.map5.sg5.vcf\n",
      "302\n",
      "SR-0003.map5.sg5.vcf\n",
      "126024\n",
      "SR-0004.map5.sg5.vcf\n",
      "0\n",
      "SR-0011.map5.sg5.vcf\n",
      "161875\n",
      "SR-0016.map5.sg5.vcf\n",
      "2403\n",
      "SR-0026.map5.sg5.vcf\n",
      "1412494\n",
      "WTF SR-0026.map5.sg5.vcf M1a1a3b1 14222364 G T G A\n",
      "WTF SR-0026.map5.sg5.vcf J1a2a1a2d2b2b2c4d2a2a5a1e4a6j2b~ 14794510 G A G C\n",
      "WTF SR-0026.map5.sg5.vcf G2a2b2a1a1b1a1b1a3~ 21212500 A . C T\n",
      "WTF SR-0026.map5.sg5.vcf R1a1a1b1a1a1c 21221843 C A C T\n",
      "WTF SR-0026.map5.sg5.vcf O1b1a1a2 21221843 C A C T\n",
      "SR-0021.map5.sg5.vcf\n",
      "825\n",
      "SR-0017.map5.sg5.vcf\n",
      "1998\n",
      "SR-0010.map5.sg5.vcf\n",
      "54789\n",
      "5540-001.map5.sg5.vcf\n",
      "350\n",
      "SR-0005.map5.sg5.vcf\n",
      "56\n",
      "SR-0002.map5.sg5.vcf\n",
      "20353\n"
     ]
    }
   ],
   "source": [
    "sampleDictionary = {}\n",
    "directory = '/Users/loftum/Desktop/LeeLab/LeonardoDaVinci/JCVI/variants/finalVCFs_Map5/'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    print(filename)\n",
    "    sampleDictionary[filename] = {}\n",
    "\n",
    "    tempList = []\n",
    "    path = os.path.join(directory, filename)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"##\"):\n",
    "                continue\n",
    "            tempList.append(line.split())\n",
    "\n",
    "    tempDF = pd.DataFrame(tempList)\n",
    "    tempDF.columns = tempDF.iloc[0]\n",
    "    tempDF = tempDF.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    tempDF1 = tempDF[~tempDF['INFO'].str.contains(\"INDEL\", na=False)].copy()\n",
    "\n",
    "    print(len(tempDF1))\n",
    "\n",
    "    for row in tempDF1.index:\n",
    "        \n",
    "        fileColumn = tempDF1.columns[-1]\n",
    "        position = str(tempDF1.at[row,'POS'])\n",
    "        ref = str(tempDF1.at[row,'REF'])\n",
    "        alt = str(tempDF1.at[row,'ALT'])\n",
    "        info = str(tempDF1.at[row,'INFO'])\n",
    "\n",
    "        if \"AD=\" not in info:\n",
    "            continue\n",
    "\n",
    "        #This will give me either just a number (1) or two numbers ('0,1')\n",
    "        AD = info.split(\"AD=\")[1].split(\";\")[0]\n",
    "\n",
    "        # reference only\n",
    "        if alt == \".\":\n",
    "            #if its invariant than the reference gets the reads\n",
    "            refCounts = int(AD)\n",
    "            altCounts = 0\n",
    "\n",
    "        #else if there is a variant the ref and alt get their respective reads\n",
    "        else:\n",
    "            refCounts, altCounts = map(int, AD.split(\",\"))\n",
    "\n",
    "        #If this position is not informative then skip otherwise continue\n",
    "        if position not in positionDict:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        if refCounts ==0 and altCounts ==0:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            #for each of the haplogroups that has this marker ID informative position\n",
    "            for group in positionDict[position]['haploGroups']:\n",
    "    \n",
    "    \n",
    "                #The MarkerID info\n",
    "                ancestralSNP = positionDict[position]['Ancestral']\n",
    "                derivedSNP = positionDict[position]['Derived']\n",
    "                marker = positionDict[position]['MarkerID']\n",
    "                \n",
    "                #if the group does not exist in our sample dictionary then make an entry for the haplogroup\n",
    "                #Keep track of how many ancestral or derived hits this group has and the different positions linked to the haplogroup\n",
    "                if group not in sampleDictionary[filename]:\n",
    "                    sampleDictionary[filename][group] = {\"Ancestral\": 0, \"Derived\": 0, 'Positions':{}}\n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "                #If the alt was a dot that means this sample carries that reference (invariant)\n",
    "                #Now check for what the reference has\n",
    "                if alt == '.':\n",
    "                    if ref == ancestralSNP:\n",
    "                        sampleDictionary[filename][group]['Positions'][position]={'MarkerID':marker,'ReferenceCounts':refCounts, 'SampleCounts':0,'AncestralSNP':ancestralSNP, 'DerivedSNP':derivedSNP, 'SampleContains':ref, 'FLAG':'invariant'}\n",
    "                        sampleDictionary[filename][group][\"Ancestral\"] += refCounts\n",
    "                    elif ref == derivedSNP:\n",
    "                        sampleDictionary[filename][group]['Positions'][position]={'MarkerID':marker,'ReferenceCounts':0, 'SampleCounts':refCounts,'AncestralSNP':ancestralSNP, 'DerivedSNP':derivedSNP,'SampleContains':ref,'FLAG':'invariant'}\n",
    "                        sampleDictionary[filename][group][\"Derived\"] += refCounts\n",
    "                    else:\n",
    "                        print('ODDITY', filename, group, position, ref, alt, ancestralSNP, derivedSNP)\n",
    "                else:\n",
    "    \n",
    "                    if alt == ancestralSNP:\n",
    "                        sampleDictionary[filename][group]['Positions'][position]={'MarkerID':marker,'ReferenceCounts':refCounts, 'SampleCounts':altCounts,'AncestralSNP':ancestralSNP, 'DerivedSNP':derivedSNP, 'ReferenceContains':ref, 'SampleContains':alt,'FLAG':'variant'}\n",
    "                        sampleDictionary[filename][group][\"Ancestral\"] += altCounts\n",
    "                        \n",
    "                    elif alt == derivedSNP:\n",
    "                        sampleDictionary[filename][group]['Positions'][position]={'MarkerID':marker,'ReferenceCounts':refCounts, 'SampleCounts':altCounts,'AncestralSNP':ancestralSNP, 'DerivedSNP':derivedSNP,'ReferenceContains':ref,'SampleContains':alt,'FLAG':'variant'}\n",
    "                        sampleDictionary[filename][group][\"Derived\"] += altCounts\n",
    "                        \n",
    "                    else:\n",
    "                        print('ODDITY', filename, group, position, ref, alt, ancestralSNP, derivedSNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525006bb-bf98-41aa-8ffa-3dba8c22222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampleKey in sampleDictionary.keys():\n",
    "    with open('/Users/loftum/Desktop/LeeLab/LeonardoDaVinci/JCVI/haplogroup_dataframes_map5/'+str(sampleKey)+'.fullInformation.ISOGG.csv', 'a+') as file:\n",
    "        file.write(\"Sample\\tMarkerID\\thgID\\tcoord\\tAncAllele\\tDerAllele\\tSampleAllele\\tAnceAlleleDP\\tDerAlleleDP\\tVarianceFlag\\n\")\n",
    "        usedHaplogroups = {}\n",
    "    \n",
    "        for row in variantDF.index:\n",
    "\n",
    "            #Unique haplogroup ID\n",
    "            hg = variantDF.at[row,'Haplogroup']\n",
    "\n",
    "            #If we already have done this haplogroup no need to do again\n",
    "            if hg in usedHaplogroups:\n",
    "                continue\n",
    "    \n",
    "            # mark as used now (prevents duplicated work)\n",
    "            usedHaplogroups[hg] = 1  \n",
    "    \n",
    "            if hg not in sampleDictionary[sampleKey]:\n",
    "                continue\n",
    "    \n",
    "            for pos, info in sampleDictionary[sampleKey][hg]['Positions'].items():\n",
    "                if str(info['SampleContains']) == str(info['AncestralSNP']):\n",
    "\n",
    "                    if str(info['FLAG']) == 'invariant':\n",
    "                        file.write(\n",
    "                            str(sampleKey)+ \"\\t\"\n",
    "                            + str(info['MarkerID']) + \"\\t\"\n",
    "                            + str(hg) + \"\\t\"\n",
    "                            + str(pos) + \"\\t\"\n",
    "                            + str(info['AncestralSNP']) + \"\\t\"\n",
    "                            + str(info['DerivedSNP']) + \"\\t\"\n",
    "                            + str(info['SampleContains']) + \"\\t\"\n",
    "                            + str(info['ReferenceCounts']) + \"\\t\"\n",
    "                            + str(info['SampleCounts']) + \"\\t\"\n",
    "                            + str(info['FLAG']) + \"\\n\"\n",
    "                        )\n",
    "                    else:\n",
    "                        file.write(\n",
    "                            str(sampleKey)+ \"\\t\"\n",
    "                            + str(info['MarkerID']) + \"\\t\"\n",
    "                            + str(hg) + \"\\t\"\n",
    "                            + str(pos) + \"\\t\"\n",
    "                            + str(info['AncestralSNP']) + \"\\t\"\n",
    "                            + str(info['DerivedSNP']) + \"\\t\"\n",
    "                            + str(info['SampleContains']) + \"\\t\"\n",
    "                            + str(info['SampleCounts']) + \"\\t\"\n",
    "                            + str(info['ReferenceCounts']) + \"\\t\"\n",
    "                            + str(info['FLAG']) + \"\\n\"\n",
    "                        )\n",
    "                        \n",
    "                else:\n",
    "                    file.write(\n",
    "                            str(sampleKey)+ \"\\t\"\n",
    "                            + str(info['MarkerID']) + \"\\t\"\n",
    "                            + str(hg) + \"\\t\"\n",
    "                            + str(pos) + \"\\t\"\n",
    "                            + str(info['AncestralSNP']) + \"\\t\"\n",
    "                            + str(info['DerivedSNP']) + \"\\t\"\n",
    "                            + str(info['SampleContains']) + \"\\t\"\n",
    "                            + str(info['ReferenceCounts']) + \"\\t\"\n",
    "                            + str(info['SampleCounts']) + \"\\t\"\n",
    "                            + str(info['FLAG']) + \"\\n\"\n",
    "                        )\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493aed55-7bde-4a42-b860-cd4f0d41ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampleKey in sampleDictionary.keys():\n",
    "    with open('/Users/loftum/Desktop/LeeLab/LeonardoDaVinci/JCVI/haplogroupSummaries_map5/'+str(sampleKey)+'.haploLevelInfo.ISOGG.csv', 'a+') as file:\n",
    "        file.write(\"Sample\\thgID\\tAnceAlleleDP\\tDerAlleleDP\\n\")\n",
    "        usedHaplogroups = {}\n",
    "    \n",
    "        for row in variantDF.index:\n",
    "\n",
    "            #Unique haplogroup ID\n",
    "            hg = variantDF.at[row,'Haplogroup']\n",
    "\n",
    "            #If we already have done this haplogroup no need to do again\n",
    "            if hg in usedHaplogroups:\n",
    "                continue\n",
    "    \n",
    "            # mark as used now (prevents duplicated work)\n",
    "            usedHaplogroups[hg] = 1  \n",
    "    \n",
    "            if hg not in sampleDictionary[sampleKey]:\n",
    "                continue\n",
    "\n",
    "            AncestralCount = sampleDictionary[sampleKey][hg]['Ancestral']\n",
    "            DerivedCount = sampleDictionary[sampleKey][hg]['Derived']\n",
    "\n",
    "            file.write(sampleKey + \"\\t\" + hg +\"\\t\" + str(AncestralCount) +'\\t' + str(DerivedCount) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cc0a7-9e20-4ae3-9e23-588634606600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
